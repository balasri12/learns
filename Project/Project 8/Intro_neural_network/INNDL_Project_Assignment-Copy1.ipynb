{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data fetching and understand the train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Balajisri\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as  pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']\n"
     ]
    }
   ],
   "source": [
    "f1 = h5py.File('SVHN_single_grey1.h5', 'r')\n",
    "print(list(f1.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape - (42000, 32, 32)\n",
      "y_train Shape - (42000,)\n",
      "X_val Shape - (60000, 32, 32)\n",
      "y_val Shape - (60000,)\n",
      "X_test Shape - (18000, 32, 32)\n",
      "y_test Shape - (18000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = f1['X_train'][:]\n",
    "print(\"X_train Shape -\",X_train.shape)\n",
    "\n",
    "y_train = f1['y_train'][:]\n",
    "print(\"y_train Shape -\", y_train.shape)\n",
    "\n",
    "X_val = f1['X_val'][:]\n",
    "print(\"X_val Shape -\", X_val.shape)\n",
    "\n",
    "y_val = f1['y_val'][:]\n",
    "print(\"y_val Shape -\", y_val.shape)\n",
    "\n",
    "X_test = f1['X_test'][:]\n",
    "print(\"X_test Shape -\", X_test.shape)\n",
    "\n",
    "y_test = f1['y_test'][:]\n",
    "print(\"y_test Shape -\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have totally 3 set of data like train, validate and test with 42000, 60000 and 18000 accordingly. dataset has the shape of 32x32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement and apply an optimal k-Nearest Neighbor (kNN) classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the image dataset in format which can used to KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train.shape\n",
    "X_train_2d = X_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test_2d = X_test.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh.fit(X_train_2d, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = neigh.predict(X_test_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the classification metric report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.68      0.53      1814\n",
      "           1       0.46      0.74      0.56      1828\n",
      "           2       0.58      0.55      0.57      1803\n",
      "           3       0.42      0.42      0.42      1719\n",
      "           4       0.65      0.64      0.64      1812\n",
      "           5       0.49      0.38      0.43      1768\n",
      "           6       0.49      0.41      0.45      1832\n",
      "           7       0.73      0.60      0.66      1808\n",
      "           8       0.46      0.35      0.40      1812\n",
      "           9       0.56      0.40      0.46      1804\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     18000\n",
      "   macro avg       0.53      0.52      0.51     18000\n",
      "weighted avg       0.53      0.52      0.51     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like KNN model has accuracy around 50% with K = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement and apply a deep neural network classifier including"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape, BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand and be able to implement (vectorized) backpropagation \n",
    "# Implement batch normalization for training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_3 (Reshape)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              1025000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,043,106\n",
      "Trainable params: 1,039,058\n",
      "Non-trainable params: 4,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model = Sequential()\n",
    "mnist_model.add(Reshape((1024,),input_shape=(32,32,)))\n",
    "mnist_model.add(BatchNormalization())\n",
    "mnist_model.add(Dense(100, activation='relu'))\n",
    "mnist_model.add(BatchNormalization())\n",
    "mnist_model.add(Dropout(0.25))\n",
    "mnist_model.add(Dense(10, activation='softmax'))\n",
    "mnist_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 2.0012 - acc: 0.3755 - val_loss: 1.3153 - val_acc: 0.5861\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 1.4001 - acc: 0.5490 - val_loss: 0.9172 - val_acc: 0.7307\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 1.2342 - acc: 0.6013 - val_loss: 0.8355 - val_acc: 0.7533\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 1.1473 - acc: 0.6351 - val_loss: 0.8046 - val_acc: 0.7619\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 1.0734 - acc: 0.6587 - val_loss: 0.7160 - val_acc: 0.7938\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 1.0298 - acc: 0.6761 - val_loss: 0.6787 - val_acc: 0.8063\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 0.9838 - acc: 0.6904 - val_loss: 0.6682 - val_acc: 0.8065\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.9669 - acc: 0.6964 - val_loss: 0.6515 - val_acc: 0.8106\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 0.9356 - acc: 0.7054 - val_loss: 0.6739 - val_acc: 0.8006\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 0.9109 - acc: 0.7161 - val_loss: 0.6164 - val_acc: 0.8217\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.8945 - acc: 0.7179 - val_loss: 0.5824 - val_acc: 0.8366\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.8732 - acc: 0.7269 - val_loss: 0.5782 - val_acc: 0.8387\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.8625 - acc: 0.7286 - val_loss: 0.5578 - val_acc: 0.8468\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.8524 - acc: 0.7334 - val_loss: 0.5478 - val_acc: 0.8496\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 0.8258 - acc: 0.7410 - val_loss: 0.5355 - val_acc: 0.8547\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.8142 - acc: 0.7451 - val_loss: 0.5393 - val_acc: 0.8512\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 0.8094 - acc: 0.7462 - val_loss: 0.5236 - val_acc: 0.8569\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7935 - acc: 0.7528 - val_loss: 0.5351 - val_acc: 0.8514\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7862 - acc: 0.7544 - val_loss: 0.5155 - val_acc: 0.8593\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 6s 148us/step - loss: 0.7811 - acc: 0.7566 - val_loss: 0.5332 - val_acc: 0.8517\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 0.7702 - acc: 0.7609 - val_loss: 0.5166 - val_acc: 0.8576\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7714 - acc: 0.7591 - val_loss: 0.5200 - val_acc: 0.8589\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7631 - acc: 0.7630 - val_loss: 0.4970 - val_acc: 0.8666\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7563 - acc: 0.7630 - val_loss: 0.5047 - val_acc: 0.8621\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7437 - acc: 0.7648 - val_loss: 0.4958 - val_acc: 0.8651\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7443 - acc: 0.7671 - val_loss: 0.4838 - val_acc: 0.8694\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7355 - acc: 0.7709 - val_loss: 0.4711 - val_acc: 0.8758\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7274 - acc: 0.7733 - val_loss: 0.4717 - val_acc: 0.8742\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7171 - acc: 0.7763 - val_loss: 0.4695 - val_acc: 0.8766\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7151 - acc: 0.7750 - val_loss: 0.4703 - val_acc: 0.8732\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7160 - acc: 0.7763 - val_loss: 0.4639 - val_acc: 0.8775\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 0.7240 - acc: 0.7733 - val_loss: 0.4577 - val_acc: 0.8776\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.7096 - acc: 0.7760 - val_loss: 0.4609 - val_acc: 0.8768\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 0.7004 - acc: 0.7793 - val_loss: 0.4503 - val_acc: 0.8817\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.6955 - acc: 0.7829 - val_loss: 0.4600 - val_acc: 0.8762\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.6960 - acc: 0.7810 - val_loss: 0.4542 - val_acc: 0.8788\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 0.6838 - acc: 0.7855 - val_loss: 0.4523 - val_acc: 0.8790\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.6857 - acc: 0.7876 - val_loss: 0.4425 - val_acc: 0.8842\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 0.6850 - acc: 0.7879 - val_loss: 0.4421 - val_acc: 0.8851\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 0.6749 - acc: 0.7897 - val_loss: 0.4304 - val_acc: 0.8887\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 7s 162us/step - loss: 0.6737 - acc: 0.7895 - val_loss: 0.4407 - val_acc: 0.8835\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.6690 - acc: 0.7898 - val_loss: 0.4593 - val_acc: 0.8749\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6761 - acc: 0.7880 - val_loss: 0.4360 - val_acc: 0.8860\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.6659 - acc: 0.7948 - val_loss: 0.4464 - val_acc: 0.8801\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 0.6657 - acc: 0.7916 - val_loss: 0.4319 - val_acc: 0.8858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23426362a58>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "mnist_model.fit(X_train,y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=50,\n",
    "          batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 7, 2, ..., 7, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = mnist_model.predict_classes(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1630,   36,    6,   18,   14,    3,   23,   25,   20,   39],\n",
       "       [  40, 1607,   13,   24,   50,    7,   10,   42,   22,   13],\n",
       "       [  24,   52, 1511,   26,   24,   13,    1,   69,   29,   54],\n",
       "       [  23,   40,   31, 1338,   17,  143,   12,   29,   51,   35],\n",
       "       [  31,   65,   26,   12, 1564,   21,   17,   11,   15,   50],\n",
       "       [  17,   28,   14,   66,   11, 1476,   52,   10,   49,   45],\n",
       "       [  63,   31,   12,   26,   32,   72, 1460,   12,  106,   18],\n",
       "       [  30,   83,   32,   13,   13,    6,    7, 1587,   18,   19],\n",
       "       [  37,   52,   22,   38,   21,   40,   91,   11, 1431,   69],\n",
       "       [  65,   40,   24,   40,   17,   34,   17,   19,   50, 1498]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1814\n",
      "           1       0.79      0.88      0.83      1828\n",
      "           2       0.89      0.84      0.86      1803\n",
      "           3       0.84      0.78      0.81      1719\n",
      "           4       0.89      0.86      0.87      1812\n",
      "           5       0.81      0.83      0.82      1768\n",
      "           6       0.86      0.80      0.83      1832\n",
      "           7       0.87      0.88      0.88      1808\n",
      "           8       0.80      0.79      0.79      1812\n",
      "           9       0.81      0.83      0.82      1804\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     18000\n",
      "   macro avg       0.84      0.84      0.84     18000\n",
      "weighted avg       0.84      0.84      0.84     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23422699c50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_test[609])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.predict_classes(np.reshape(X_test[609],(-1,32,32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network performance well when compared with tradition machine learning model - KNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: \n",
    " - KNN has the accuracy around 50%\n",
    " - Neural Network has the accuracy around 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also KNN model is slow while predicting when compared but Neural network is fast and more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
