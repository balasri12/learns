{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data fetching and understand the train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Balajisri\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as  pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']\n"
     ]
    }
   ],
   "source": [
    "f1 = h5py.File('SVHN_single_grey1.h5', 'r')\n",
    "print(list(f1.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape - (42000, 32, 32)\n",
      "y_train Shape - (42000,)\n",
      "X_val Shape - (60000, 32, 32)\n",
      "y_val Shape - (60000,)\n",
      "X_test Shape - (18000, 32, 32)\n",
      "y_test Shape - (18000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = f1['X_train'][:]\n",
    "print(\"X_train Shape -\",X_train.shape)\n",
    "\n",
    "y_train = f1['y_train'][:]\n",
    "print(\"y_train Shape -\", y_train.shape)\n",
    "\n",
    "X_val = f1['X_val'][:]\n",
    "print(\"X_val Shape -\", X_val.shape)\n",
    "\n",
    "y_val = f1['y_val'][:]\n",
    "print(\"y_val Shape -\", y_val.shape)\n",
    "\n",
    "X_test = f1['X_test'][:]\n",
    "print(\"X_test Shape -\", X_test.shape)\n",
    "\n",
    "y_test = f1['y_test'][:]\n",
    "print(\"y_test Shape -\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have totally 3 set of data like train, validate and test with 42000, 60000 and 18000 accordingly. dataset has the shape of 32x32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement and apply an optimal k-Nearest Neighbor (kNN) classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the image dataset in format which can used to KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train.shape\n",
    "X_train_2d = X_train.reshape((nsamples,nx*ny))\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test_2d = X_test.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh.fit(X_train_2d, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = neigh.predict(X_test_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the classification metric report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.68      0.53      1814\n",
      "           1       0.46      0.74      0.56      1828\n",
      "           2       0.58      0.55      0.57      1803\n",
      "           3       0.42      0.42      0.42      1719\n",
      "           4       0.65      0.64      0.64      1812\n",
      "           5       0.49      0.38      0.43      1768\n",
      "           6       0.49      0.41      0.45      1832\n",
      "           7       0.73      0.60      0.66      1808\n",
      "           8       0.46      0.35      0.40      1812\n",
      "           9       0.56      0.40      0.46      1804\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     18000\n",
      "   macro avg       0.53      0.52      0.51     18000\n",
      "weighted avg       0.53      0.52      0.51     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like KNN model has accuracy around 50% with K = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement and apply a deep neural network classifier including"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape, BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand and be able to implement (vectorized) backpropagation \n",
    "# Implement batch normalization for training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 231,406\n",
      "Trainable params: 228,758\n",
      "Non-trainable params: 2,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model = Sequential()\n",
    "mnist_model.add(Reshape((1024,),input_shape=(32,32,)))\n",
    "mnist_model.add(BatchNormalization())\n",
    "mnist_model.add(Dense(200, activation='relu'))\n",
    "mnist_model.add(BatchNormalization())\n",
    "mnist_model.add(Dense(100, activation='relu'))\n",
    "mnist_model.add(BatchNormalization())\n",
    "mnist_model.add(Dropout(0.25))\n",
    "mnist_model.add(Dense(10, activation='softmax'))\n",
    "mnist_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 11s 272us/step - loss: 1.7948 - acc: 0.3968 - val_loss: 1.1362 - val_acc: 0.6545\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 1.2761 - acc: 0.5878 - val_loss: 0.9868 - val_acc: 0.7018\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 1.1233 - acc: 0.6380 - val_loss: 0.8276 - val_acc: 0.7518\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 1.0418 - acc: 0.6664 - val_loss: 0.7838 - val_acc: 0.7646\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.9801 - acc: 0.6879 - val_loss: 0.6937 - val_acc: 0.7953\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.9354 - acc: 0.7034 - val_loss: 0.6739 - val_acc: 0.8010\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.8974 - acc: 0.7141 - val_loss: 0.7082 - val_acc: 0.7864\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.8607 - acc: 0.7255 - val_loss: 0.6166 - val_acc: 0.8153\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.8370 - acc: 0.7354 - val_loss: 0.5956 - val_acc: 0.8257\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.8162 - acc: 0.7396 - val_loss: 0.6287 - val_acc: 0.8076\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.7968 - acc: 0.7480 - val_loss: 0.5898 - val_acc: 0.8202\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.7830 - acc: 0.7505 - val_loss: 0.5486 - val_acc: 0.8350\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.7568 - acc: 0.7611 - val_loss: 0.5407 - val_acc: 0.8373\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.7409 - acc: 0.7647 - val_loss: 0.5377 - val_acc: 0.8379\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.7383 - acc: 0.7653 - val_loss: 0.6075 - val_acc: 0.8163\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.7256 - acc: 0.7700 - val_loss: 0.5083 - val_acc: 0.8478\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 7s 158us/step - loss: 0.7066 - acc: 0.7759 - val_loss: 0.5157 - val_acc: 0.8451\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6977 - acc: 0.7801 - val_loss: 0.4714 - val_acc: 0.8598\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6952 - acc: 0.7795 - val_loss: 0.4634 - val_acc: 0.8654\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6776 - acc: 0.7876 - val_loss: 0.4745 - val_acc: 0.8589\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6663 - acc: 0.7874 - val_loss: 0.4636 - val_acc: 0.8632\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6646 - acc: 0.7889 - val_loss: 0.4486 - val_acc: 0.8686\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6588 - acc: 0.7909 - val_loss: 0.4443 - val_acc: 0.8678\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.6485 - acc: 0.7943 - val_loss: 0.4918 - val_acc: 0.8511\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6432 - acc: 0.7967 - val_loss: 0.4552 - val_acc: 0.8645\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6379 - acc: 0.7964 - val_loss: 0.4526 - val_acc: 0.8625\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6333 - acc: 0.7967 - val_loss: 0.4578 - val_acc: 0.8634\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 7s 160us/step - loss: 0.6194 - acc: 0.8030 - val_loss: 0.4214 - val_acc: 0.8768\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6212 - acc: 0.8025 - val_loss: 0.4188 - val_acc: 0.8766\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6077 - acc: 0.8055 - val_loss: 0.4507 - val_acc: 0.8646\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6034 - acc: 0.8092 - val_loss: 0.4069 - val_acc: 0.8802\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.6028 - acc: 0.8078 - val_loss: 0.4341 - val_acc: 0.8710\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.5990 - acc: 0.8093 - val_loss: 0.3949 - val_acc: 0.8847\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 7s 159us/step - loss: 0.5861 - acc: 0.8148 - val_loss: 0.4131 - val_acc: 0.8774\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 7s 168us/step - loss: 0.5906 - acc: 0.8115 - val_loss: 0.3921 - val_acc: 0.8873\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 7s 176us/step - loss: 0.5887 - acc: 0.8134 - val_loss: 0.4331 - val_acc: 0.8703\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 7s 175us/step - loss: 0.5818 - acc: 0.8130 - val_loss: 0.3780 - val_acc: 0.8884\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 8s 188us/step - loss: 0.5694 - acc: 0.8196 - val_loss: 0.3773 - val_acc: 0.8897\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 7s 178us/step - loss: 0.5747 - acc: 0.8159 - val_loss: 0.4427 - val_acc: 0.8666\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 7s 177us/step - loss: 0.5694 - acc: 0.8203 - val_loss: 0.3726 - val_acc: 0.8905\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 7s 176us/step - loss: 0.5689 - acc: 0.8183 - val_loss: 0.3766 - val_acc: 0.8890\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 7s 176us/step - loss: 0.5658 - acc: 0.8195 - val_loss: 0.3730 - val_acc: 0.8920\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 8s 179us/step - loss: 0.5574 - acc: 0.8200 - val_loss: 0.3706 - val_acc: 0.8909\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 8s 179us/step - loss: 0.5542 - acc: 0.8245 - val_loss: 0.3645 - val_acc: 0.8949\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 7s 177us/step - loss: 0.5557 - acc: 0.8227 - val_loss: 0.3975 - val_acc: 0.8801\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 7s 176us/step - loss: 0.5474 - acc: 0.8240 - val_loss: 0.4083 - val_acc: 0.8801\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 7s 175us/step - loss: 0.5458 - acc: 0.8261 - val_loss: 0.3699 - val_acc: 0.8912\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 7s 177us/step - loss: 0.5400 - acc: 0.8269 - val_loss: 0.3771 - val_acc: 0.8876\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 7s 177us/step - loss: 0.5406 - acc: 0.8273 - val_loss: 0.3890 - val_acc: 0.8857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1daa787ab38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "mnist_model.fit(X_train,y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=50,\n",
    "          batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 7, 2, ..., 7, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = mnist_model.predict_classes(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1635,   28,   11,    9,   16,   10,   18,   25,   20,   42],\n",
       "       [  27, 1620,   17,   19,   44,   14,    7,   44,   20,   16],\n",
       "       [  16,   28, 1581,   24,   23,   16,    4,   48,   17,   46],\n",
       "       [  16,   56,   44, 1319,   19,  118,   19,   45,   51,   32],\n",
       "       [  15,   48,   25,   21, 1602,   21,   20,   17,   13,   30],\n",
       "       [  15,   18,    9,   68,   27, 1455,  100,   16,   39,   21],\n",
       "       [  56,   22,    8,   21,   29,   94, 1497,   18,   66,   21],\n",
       "       [  14,   59,   35,   22,   13,   17,    4, 1617,    9,   18],\n",
       "       [  29,   43,   20,   31,   16,   53,   64,   14, 1449,   93],\n",
       "       [  61,   39,   26,   22,   21,   38,   11,   19,   46, 1521]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88      1814\n",
      "           1       0.83      0.89      0.86      1828\n",
      "           2       0.89      0.88      0.88      1803\n",
      "           3       0.85      0.77      0.81      1719\n",
      "           4       0.89      0.88      0.88      1812\n",
      "           5       0.79      0.82      0.81      1768\n",
      "           6       0.86      0.82      0.84      1832\n",
      "           7       0.87      0.89      0.88      1808\n",
      "           8       0.84      0.80      0.82      1812\n",
      "           9       0.83      0.84      0.83      1804\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     18000\n",
      "   macro avg       0.85      0.85      0.85     18000\n",
      "weighted avg       0.85      0.85      0.85     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dae67922b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHiJJREFUeJztnVuMXNeVnv916tLV9wvJJlskRYqyNJbgRLJBaIwocDzjyUBjDCAbiAf2g6EHYzgIxkAMTB4EB4gdIA+eILbhh8ABHQvWBB5f4gssZJTMCBo7ghNAMq2IpGRqJFLivdlN9r27uu4rD10KKHL/u4vs7mrK+/8AgtV71T5n1T571anaf621zd0hhEiPbLsdEEJsDwp+IRJFwS9Eoij4hUgUBb8QiaLgFyJRFPxCJIqCX4hEUfALkSj5jXQ2s8cAfANADsB/cfevxJ4/Opb53n3hU7Yi/VqwYLt7uB0A6shxm/OX3Yock1GwJrX1WJ3aipF+7DUDQCPyns38j72qnPHRN/BfgHrkqHUPj38tMvYxcpEZEvOf2UqxPpHXVY38InbVC9QWG6sCwvMgi/jI5vDVS1UszjY6msS3HfxmlgPwnwD8cwAXAfzKzJ5x99+wPnv35fGjv9kZtFXIZAGAcis8qJXIYF9pDFPb5fpo5FxFastIIOwuLNA+9xanqe1AfpHaKs4D/Gqrj9rKrZ5gexYJnpFcmdpKkTeo2DW73AiP8YXaDtonNtkHs1VqG8pVqG0stxxsf39hhfYZMD6vzjUa1HayNkFtsRvOrlx4Hgxl/HVdIuP75Cdfp31uZCMf+x8BcNrd33L3GoDvA3h8A8cTQnSRjQT/XgAXrvv7YrtNCPEeYCPBH/pecdPnYjM7YmbHzOzY3Gzsm70QoptsJPgvAth/3d/7AFy+8UnuftTdD7v74dExiQtC3ClsJBp/BeA+M7vHzIoAPg3gmc1xSwix1dz2ar+7N8zs8wD+FmtS31Pu/lqsTwt8hTgmsdWIbNeMyCfNyPvaQrOX2o7P76O2y8tDwfb+Yo32+cj4aWr72CAfrthq9K4ct11sVIPtV5ph3wHglcoBajtf5avzU1V+zIV6KdhezLh6cHfvLLWNF7myEJNMyxZWP1ZaYRUAAAoZX9GvRhSOVkShYdInwGXpxVZ4DAHgamMw2N6I+HAjG9L53f1ZAM9u5BhCiO1BX8KFSBQFvxCJouAXIlEU/EIkioJfiETZ0Gr/ZhKT7RjzzX5qKxiXay6u8sSe46f3U1thKpzwMVvkmV7/4wGeKPTA+276TdT/5x8VeLLNaI4n9gBhGfBSk4/v38++n9pePs/Ho74QltEAwGoku7DF/Th5kCdIPbr3bWpr9fJ72CGSWLVAksUA4M36ALX9YukBajuxwH/dHpOy+/JhqfhAH5c+/2Fpd7B9vnGK9rkR3fmFSBQFvxCJouAXIlEU/EIkioJfiETp6mp/C4YlUiYrlogz2wyvvl6oj9E+x5f4KvX/euM+aht4na/O98yGV/VXx7nv5So/Xuw1LzmvfVBp8KSUZ1feF2x/aeke2ufU1fDKMRBf0c/K3P98Oby6XVzkq96rqyPU9vM6v2bZQa62fKB0IdgeK/P20tK93I/z4fEFgPJMRIXJuI+WD9veGNlF+6wsh5N+KrXOQ1p3fiESRcEvRKIo+IVIFAW/EImi4BciURT8QiRKd6U+N7rLTmzLq8VmWNaYrHFp6H+f5dJW/6u8NtroGzwhKKuFJZnKTp4k0tfD6/vFko9mm/yYr9f2UNtzsw8G29+Y4bJRpcrPlQ3w7ca8FKlZVwhPreICr2U3dIaasJDxZJsre8L17ADgQj1cg/D1Vb67zguXDlFb9W1+rmIlsn3ZMJduvRS2MTkPAHyWSMiNzu/nuvMLkSgKfiESRcEvRKIo+IVIFAW/EImi4BciUTYk9ZnZWQBLAJoAGu5+eJ0eaJLthPqNS2I5C0tsKw2ecRbLRhu+yjOsSte4H56FpRzPuFQ2XKpQW2ybqdj2Wv9niWeWvTYdlgGXr/F6h8hzGarQy6U+K3D/iSoKRLatGrjMpc/KDj7GF5e45Hu8N5zdeXLuLtqn/CY/3uDbXM5rcDUStZ18zvUMh+eIRcpa1utkfvPT3MRm6Py/5+7XNuE4Qoguoo/9QiTKRoPfAfydmf3azI5shkNCiO6w0Y/9j7r7ZTMbB/Ccmb3u7i9c/4T2m8IRABi/647ZJkCI5NnQnd/dL7f/nwbwUwCPBJ5z1N0Pu/vh4TEFvxB3Crcd/GbWb2aD7zwG8IcAXt0sx4QQW8tGbsW7AfzU1vSIPIC/dvf/uSle3UAOYSlqNZL5Fntba3IVEJ6P6CtEEYvs/ISeHJevahHZK2a7WOZS1PJ0WNLrucKdbPRzqa+xKyJR9XEZMFcMHzPyspCrcD9yXIFFucZf2+XVcKHOyTkupQ6c53Ng+Bx/zfP3RrIj+3m/HUPhLdZixV/Jbmi3xG0Hv7u/BeChjbsghNgOJPUJkSgKfiESRcEvRKIo+IVIFAW/EInS1V/dOIAWeb9pYhO0i+vIR6SV6hiXZOp9fEgKy0S2i7iekYxEAKhENMJSxv1vkcxIAMgth7W0nlnaJZo+1ihw+W3PyCK11ZthPyYnuM66cIhLW6sRyfF9wwvUtqMnLKO1Wvw1l2YjWY4LkYKmxq9nbz/XKvcOhP0/3xqlfbLGxuNFd34hEkXBL0SiKPiFSBQFvxCJouAXIlG6utqfwVGy8GppKbJ1VV9WDbaPFMq0z46RZWqbGe6lttjbYW417HtWjxwvAlM+AGAo47X/SvlIQg3ZMipf4avltcjKd39feOwB4CPjp6mNbb/2fI7X/Ts7vJPahkb5tf7dsbPUlrPwyn2LqBEA0LPIV/vzy5Eaj7k+ahvs5dfzff1Xg+0zFV53cYa5eAs1/HTnFyJRFPxCJIqCX4hEUfALkSgKfiESRcEvRKJ0V+ozp7JdKbJ1FZMHD5ZmaJ9zg2PUNt2/g9pYnT4AyObDSSL5VV4PrtHi768158MfS3RarJWorbgQ7lea5ePb6OWyV73BbXuLc9S2Jz8fbO+Z4DLl9A4+ji3n47G7wBN7zlTGg+3NBZ6E03eBy8TZFM+QylV4bcUYPVlY5o69ZlbTMJJHdhO68wuRKAp+IRJFwS9Eoij4hUgUBb8QiaLgFyJR1pX6zOwpAH8MYNrdP9BuGwPwAwAHAZwF8CfuznWfDohJW6ye3XAuLL0BwGhxldo8z/WQrMltthzOLMuXeZ/FKpfl5ho8a6se2ddqcpFLYnkyJLka97Gwwm3lGp8iJeMZbuO5pWD7UCS7bWyAZ+5dboS33Vrzg8uH1xqDwXZr8vlmK9xHX+E+xuZOLqLBsfkdq/9YWA77T5IYw8fv4DnfAfDYDW1PAnje3e8D8Hz7byHEe4h1g9/dXwBw4y8bHgfwdPvx0wA+scl+CSG2mNv9zr/b3ScBoP1/+GdUQog7li1f8DOzI2Z2zMyOzUd+YiqE6C63G/xTZjYBAO3/p9kT3f2oux9298MjY5HN2YUQXeV2g/8ZAE+0Hz8B4Geb444Qolt0IvV9D8BHAew0s4sAvgTgKwB+aGafA3AewKc6OVnTM8w3w0UOR3JcQuknktJ4PiwnAcBSg28LlVvin0CsEflq0hcu1NksctlodpkXdbxWH6C2k0t7qa1c4dtalUiyWlbnslFk9y80ynyK/PXl36W2w2Png+2P9J+hfWoRefOhIs/gfLPBx5GNseciBU338uy8HiL3AkCOK4Qo13gW4YVKOAO12ohkfZLpHUkEvIl1g9/dP0NMH+v8NEKIOw39wk+IRFHwC5EoCn4hEkXBL0SiKPiFSJSuFvBswVDxsOQRy2LLkX38ski1zcE832Ou1cf7Nfq4H62hsGxX5bVCsWeYy5HjxUVqe3uFFxmtzfFMwV6iVFok46z3Gh+PvjNcVnyjso/a3t4V9v/YrrtpnwMDvDhmZfQ4t5E5BfA9A+lAAajs5MfLL0SuyxDX2UZKfD7uL4Vf9/neUdpnZhNu27rzC5EoCn4hEkXBL0SiKPiFSBQFvxCJouAXIlG6LvWVW+F0pFhWXw5hmSoXqVY4UuDH8x4u87QKXOpzYmv0chlt/wCvazqc40VGY8UbY1mJQxfCsmjfa5O0T2skXOQSABolnuFmEXm2Ph8uTvrmJZ7l+EaRS4e/uptLhI8fOMn9ID4WSuFxAoDVMS5vFue5zBrZehH1yJ6NS83wMWP7PG4GuvMLkSgKfiESRcEvRKIo+IVIFAW/EInS1dX+pmdYbIXr4I21lmm/XBZe1Y8ldMRWy2Pky1wJyM2Ek3Ry1chqeWvzKxbHtmTqvRIuJNe8MkX7ZP3hawIA9X6erFIb4WPcKoRthSV+vynwKYD5Jk9yOT/OM6vGiuH9y0q9fKux6ijfRq02HAmZyHWZXeLHvDQSVlTmKvy60LqLt1DDT3d+IRJFwS9Eoij4hUgUBb8QiaLgFyJRFPxCJEon23U9BeCPAUy7+wfabV8G8KcArraf9kV3f3a9YzmMJlrUwSUxJumtkCQhAFiJbNeFGn/PK87xZJvW5SvB9sLSXbTPbJUnsiw0uZSTj+h5TEZbM4Zt1huR88a5VLk6zrWj5l4+VkaGuHmJJ8aUZvi58ivctlDnx5woLQTbd/TzxK9LozyZqTrM504W2emtssjn4/nlsIw5t8TnTp64H5OBb6STO/93ADwWaP+6uz/c/rdu4Ash7izWDX53fwEAL6sqhHhPspHv/J83sxNm9pSZ8Z9fCSHuSG43+L8J4F4ADwOYBPBV9kQzO2Jmx8zs2PIc/0mlEKK73Fbwu/uUuzfdvQXgWwAeiTz3qLsfdvfDA6O8QooQorvcVvCb2cR1f34SwKub444Qolt0IvV9D8BHAew0s4sAvgTgo2b2MAAHcBbAn3VyMoMjF0t9ukVaNLUJWIxIfVklItdUeW23ViWcMZfVaRdUm3yIr9W5xBbNSoxkbnku/NqyIX6uyk7+iay6g1+vsdFwxhxAFUfMT/HrUuA7m6GU5y96cmWI2u4fmA627yhx38+O8jlQG+SZpLkqv2aFq7zf24WdwfYsMlZj58LXJXcL36zXDX53/0yg+dudn0IIcSeiX/gJkSgKfiESRcEvRKIo+IVIFAW/EInS1QKeGRx9WTVoKyBSOJNs19WMvHct1yNSXyOildmt21pcxYlKdtHMwwixzC1rEmNPRM4b4uPYGuHa0YFhnvJRaYYHZd54sc3eWT4HSgv8ulyc5L8unxoJy4DDhbBsCwAD41wGLM8NU1vvdCQrMVKc1K+E58HAOX68gXPhtL6s2rmUrju/EImi4BciURT8QiSKgl+IRFHwC5EoCn4hEqWrUl/OWhjJhSWKUiw1jsCKgQJAI2LzjMtvXuD9sr5wQcUmrx8ZLcRZbfHh78ki2YWRAp6tYtj/ZmT/ueool5R6B8PSLADsKfE0PJZV6XnueywrLr/C50dhil+AmUPh13149Bzts/Mg1+V+2XuI2i5f2EFtiMnLOSJlT0U15HC79uoTQqyHgl+IRFHwC5EoCn4hEkXBL0SidHe1Hy0MZeGEiiHjq8qLfusJMMXIanlECECrwN8P8yWygn2bb6FZbEuumFpR5KvizVK4n7GieutQrfAV54tlvq1VrRX2I1Y/Mb/Ck4hyq5HV/kW+FRkb40f6ztA+7y/OUdvvDZ6itufHH6S22RpXW1aa4aSrF+1e2qfvSljhaP6m88moO78QiaLgFyJRFPxCJIqCX4hEUfALkSgKfiESpZPtuvYD+CsAewC0ABx192+Y2RiAHwA4iLUtu/7E3blGsg4rziUllsAzSGRDABgscOnQIkkWzhImABjZ8qoQqc/WH/Hjd/qmqO0XM/fzgxa4RFgbDl/S4gKX0QrLkUShekSay3jNvdVG+HrmV2kX5Ja5j1mZj2NxkW/XxWoJ7s0v0j6RdBrsyfF+nxp9idpiSWgvr94TbD8zEd7GCwBWiC1WT/JGOrnzNwD8hbs/AODDAP7czB4E8CSA5939PgDPt/8WQrxHWDf43X3S3V9uP14CcArAXgCPA3i6/bSnAXxiq5wUQmw+t/Sd38wOAvgggBcB7Hb3SWDtDQLA+GY7J4TYOjoOfjMbAPBjAF9wd/7F5+Z+R8zsmJkdm4/UZRdCdJeOgt/MClgL/O+6+0/azVNmNtG2TwAIboTu7kfd/bC7Hx4Zi/yoXgjRVdYNfjMzAN8GcMrdv3ad6RkAT7QfPwHgZ5vvnhBiq+gkq+9RAJ8FcNLMXmm3fRHAVwD80Mw+B+A8gE+td6DM+HZdMSmk7mE3V1p8C6qrlQHuR6RcYDT7rR7OFLTIt5mlOq8vt9Dk2WgTvQvU9nrfbmpb2R0ekyxyrvoAlzeziKyYzzrfGuodYlJUs58bvYfPjypPLqTbpZ2p83p7V8gcBYCZJp9XMYqRSTKYC+ufewf5HDg1HPY/lrF6I+sGv7v/Erws4Mc6P5UQ4k5Cv/ATIlEU/EIkioJfiERR8AuRKAp+IRKlqwU882hhB5FRZlq3XqSzFXnv6svzDLFmKbJdVySrz5fD6Xu5WmQLqkiRzh7jRUbv6uEyT77AZSMmpTV6+FjF5LdcPiJR5bkklpExPt1z61uNAQBR7AAAjT5uXKyGpda/mXuI9pmrhbdlA4Crq1zqi0mfE338eu7uCW971ohUhs3qZJ7eQp1W3fmFSBQFvxCJouAXIlEU/EIkioJfiERR8AuRKF2V+hyGJskRakVkjUJEEmP0R6S+1gCXr+pDXPcq5MlwReSVcp1nHlZJtiIAjOZXqK23h7+2CtkSrlGKSJiRTDBv8etSJfvxAUClGX5tVKICkNW5VJZV+RyIZVXOroRlu7+f+R3e6TzPgOyZ4/43uEKI0/t5JubuPfPB9pUqnzssMzUmid50jM6fKoT4bULBL0SiKPiFSBQFvxCJouAXIlG6utrfhGGe1N2rRLbrahIloBBb5o2R8SXR+kBkSEaHg82xFda5Ml85nqnxJJGJQngFGAD2D/EkkRO7x4Lt+dVIYk/kJTcbvN9UmW+TtVgLJ2rly3y1PFe5dVUHAKzFj1leDvuRTfFEsl0n+AUduMC3iFu5ix/zai+f38sj4X7VCu+T9Yd9jIhmNx+j86cKIX6bUPALkSgKfiESRcEvRKIo+IVIFAW/EImyrtRnZvsB/BWAPQBaAI66+zfM7MsA/hTA1fZTv+juz8aO5eDbcpWM76GVsTp4EaUvH6mdh4g0lDW4zGON8AlzvJQd3S4KAD7Qf5HaDhWD+54CAPb1cRnw+FB4HBu9XIZqFSOvOSKL1iKJPbVG2Ba9LAV+L2r08akaq+FH6x1G5k5xMbJF2RK/2J7xMW4M8hNO9JeD7bPgmUK1HJGQ+dS+iU50/gaAv3D3l81sEMCvzey5tu3r7v4fOz+dEOJOoZO9+iYBTLYfL5nZKQB7t9oxIcTWckvf+c3sIIAPAnix3fR5MzthZk+Z2egm+yaE2EI6Dn4zGwDwYwBfcPdFAN8EcC+Ah7H2yeCrpN8RMztmZsfmZ259S2chxNbQUfCbWQFrgf9dd/8JALj7lLs33b0F4FsAHgn1dfej7n7Y3Q+P7JC4IMSdwrrRaGYG4NsATrn7165rn7juaZ8E8OrmuyeE2Co6We1/FMBnAZw0s1fabV8E8BkzexhrCt5ZAH+23oHWaviF329yEe2F1fdbiWzxtdTgttwCf9m9U6vU5ovhbZV6ItJQPSL1PVw6T20xhvLcx0Ivk/p4PbgY3uTaUa3Jpb4Wqf0XqxdYG+U+ro7xa+Z7eKbd+Gj4ml2a5/OjPM6d9DzPxFzex++lxbGwnAcAO3vD28Ct1HhWX4tlR97CN+tOVvt/ibB6GNX0hRB3NvoSLkSiKPiFSBQFvxCJouAXIlEU/EIkSlcLeLbcsNQq3XK/pWY4g2myNkL7vDa9h9oGz3H5Kj+9SG1eCWd09U7xTK+L04PUdra+k9piBU37cny7rvv3XA22vzbHx704G9HfFrkfU/lwQVMAaFbDx+yLZEDW+/i9qLyHX7OJXbyg6aHha8H2qWFefHRlIpJNN8xDZnUP19mGevkLrzTDY1yuRORqbdclhLhdFPxCJIqCX4hEUfALkSgKfiESRcEvRKJ0VepreA4zjXBWVN25K+drO4LtJxfuon3K57iUs/sal2QaO7k0l+sPy2WNXi6V9Uzy1/WdS/+E2g4MzFLbod6wfAUA/2znG8H26bt5Ntq1enh/PwAoLPD7Q3aN70PYQ9TIIldSsRqp91Ce4NfsoSE+VmPFcDbd6PAK7XNtN5fYmku3d7+cm+LzcX42fG28zOdViSi32qtPCLEuCn4hEkXBL0SiKPiFSBQFvxCJouAXIlG6KvXVPYfJenhvj2ZEozi/Gpai3pzZRfvkVnkW2OIBbpu7v5/a2FtlK89TqepDXKJ6a4pn9fXleebejgKXqXqyRrD9/tFwth8ALO7hGX/NMpcIS1xxRK4SHpPaCB/7lbt5EdfecV4Ac6jAC3gy7hrgmuP8OJcwGy2e8ddzjc/hwgVuY0VNa8ORfRKHw/MqViD1RnTnFyJRFPxCJIqCX4hEUfALkSgKfiESZd3VfjMrAXgBQE/7+T9y9y+Z2T0Avg9gDMDLAD7r7nyJGu3V/lq47ttsja+iXlrhtfqo34f4ijgKfFV5pJevHA8Vw3XYBou8TykXXn0H+Mr8elys8PFotMLLvbNVPr79kfpyy/fw1fnlvZHtuhrh+0pW4OrH6BBf0R+OXJdqk0/jpof9r5FxWg+PKDuNfm7zHB9HzxFlZIyP1eC+sFqRFfncvum5HTynCuD33f0hrG3H/ZiZfRjAXwL4urvfB2AOwOc6PqsQYttZN/h9jXd2Eiy0/zmA3wfwo3b70wA+sSUeCiG2hI6+85tZrr1D7zSA5wCcATDv7u98br0IYO/WuCiE2Ao6Cn53b7r7wwD2AXgEwAOhp4X6mtkRMztmZsdW5yJF24UQXeWWVvvdfR7ALwB8GMCImb2z0rIPwGXS56i7H3b3w72jvEKKEKK7rBv8ZrbLzEbaj3sB/AGAUwB+DuBftJ/2BICfbZWTQojNp5PEngkAT5tZDmtvFj909/9uZr8B8H0z+/cA/i+Ab693oNVmAafmw9toXVnitfPK5fAnBicyDgDs3sG3cLonWvONS4SjhbAUlYW/8QAAqi0+xMtN/klousrHY67CZTvGSr1Iba1WJCElIovGbE6GJJ/j8lUxz4+Xz3i/Fvg8YHJqLHFqILKn2MIIlwjreb61WaMWkfqIfJgNkj25APSRIolZ1vl+XesGv7ufAPDBQPtbWPv+L4R4D6Jf+AmRKAp+IRJFwS9Eoij4hUgUBb8QiWLONJmtOJnZVQDn2n/uBBCpAtc15Me7kR/v5r3mxwF358Utr6Orwf+uE5sdc/fD23Jy+SE/5Ic+9guRKgp+IRJlO4P/6Dae+3rkx7uRH+/mt9aPbfvOL4TYXvSxX4hE2ZbgN7PHzOwfzOy0mT25HT60/ThrZifN7BUzO9bF8z5lZtNm9up1bWNm9pyZvdn+P7yv2db78WUzu9Qek1fM7ONd8GO/mf3czE6Z2Wtm9q/a7V0dk4gfXR0TMyuZ2Utmdrztx79rt99jZi+2x+MHZsZTNTvB3bv6D0AOa2XADgEoAjgO4MFu+9H25SyAndtw3o8A+BCAV69r+w8Anmw/fhLAX26TH18G8K+7PB4TAD7UfjwI4A0AD3Z7TCJ+dHVMABiAgfbjAoAXsVZA54cAPt1u/88A/uVGzrMdd/5HAJx297d8rdT39wE8vg1+bBvu/gKAG4sKPI61QqhAlwqiEj+6jrtPuvvL7cdLWCsWsxddHpOIH13F19jyornbEfx7AVy47u/tLP7pAP7OzH5tZke2yYd32O3uk8DaJAQwvo2+fN7MTrS/Fmz514/rMbODWKsf8SK2cUxu8APo8ph0o2judgR/qKTJdkkOj7r7hwD8EYA/N7OPbJMfdxLfBHAv1vZomATw1W6d2MwGAPwYwBfcne+h3X0/uj4mvoGiuZ2yHcF/EcD+6/6mxT+3Gne/3P5/GsBPsb2ViabMbAIA2v9Pb4cT7j7VnngtAN9Cl8bEzApYC7jvuvtP2s1dH5OQH9s1Ju1z33LR3E7ZjuD/FYD72iuXRQCfBvBMt50ws34zG3znMYA/BPBqvNeW8gzWCqEC21gQ9Z1ga/NJdGFMzMywVgPylLt/7TpTV8eE+dHtMela0dxurWDesJr5caytpJ4B8G+2yYdDWFMajgN4rZt+APge1j4+1rH2SehzAHYAeB7Am+3/x7bJj/8K4CSAE1gLvoku+PFPsfYR9gSAV9r/Pt7tMYn40dUxAfCPsVYU9wTW3mj+7XVz9iUApwH8NwA9GzmPfuEnRKLoF35CJIqCX4hEUfALkSgKfiESRcEvRKIo+IVIFAW/EImi4BciUf4fsaL+BjBFN+gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_test[609])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.predict_classes(np.reshape(X_test[609],(-1,32,32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network performance well when compared with tradition machine learning model - KNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: \n",
    " - KNN has the accuracy around 50%\n",
    " - Neural Network has the accuracy around 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also KNN model is slow while predicting when compared but Neural network is fast and more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
